![](../Images/Pasted%20image%2020231002011959.png)
- Language agents are a promising step towards artificial general intelligence (AGI) and can help reduce human effort in certain roles such as customer service, consulting, programming, writing, teaching, etc.
- While intriguing, most of these demos or repositories are not friendly for customizing, tuning, and deploying new agents even for experienced developers or researchers. This limitation comes from the fact that these demos typically proof-of-concepts showcasing the possibility of language agents, instead of being larger frameworks that can be used to build and customize language agents over time.
- In addition, most (if not all) existing language agent frameworks solely depend on a short task description and rely completely on the abilities of LLMs to plan and act. This results in significant randomness and inconsistency across different runs, delivering an unsatisfactory user experience and making it hard to customize and tune language agents.
- AGENTS’s philosophy is to make customizing, tuning, and deploying language agents as simple as possible even for non-specialists while also remaining easily extensible for developers and researchers. In addition, the library also provides the following key features that make it a versatile framework for language agents:
	- <span style="color:#ffc000">Long-short term memory</span> - integrates the memory components in and enables language agents to store and retrieve long-term memory with VectorDB and semantic search, and regularly update a short-term working memory with a scratchpad. Users can choose to equip an agent with long-term memory, short-term memory, or both of them by simply filling in a field in the config file.
		- Specifically, long-term memories are action histories and are embedded by sentence-transformers stored in a VectorDB, and queried via semantic search. Short-term memories, or working memories, are in natural language form and updated by an LLM via a carefully tuned prompt.
	- <span style="color:#ffc000">Tool usage and Web navigation</span> - supports a few commonly used external APIs and provides an abstract class that enables developers to integrate other tools with ease. We also enable agents to navigate the internet and gather information by defining web search and web navigation as specialized APIs.
		- supports tool usage and web navigation via ToolComponents. For each external tool or API, developer can wrap the API call in theToolComponent.func() method. For complicated tools of which the API call is context dependent, AGENTS integrates the the “Function-calling” feature of OpenAI’s GPT APIs to let LLMs decide how to use the tools. Web navigation is achieved by implementing web search as a specialized tool.
	- <span style="color:#ffc000">Multi-agent communication</span> - also supports customizing multi-agent systems. One new feature for multi-agent communication in AGENTS is the “dynamic scheduling” feature. Instead of scheduling the order for the agents to act with hard-coded rules, dynamic scheduling provides an option to define a controller agent that acts as a “moderator” and decides which agent to perform the next action considering their roles and the current history. Dynamic scheduling has the potential to make communication between multiple agents more natural and flexible. Developers can easily customize the controller by specifying its rule in the config file using natural language.
		- includes a controller function that dynamically decides which agent will perform the next action using an LLM by considering the previous actions, the environment, and the target of the current states. This makes multi-agent communication more flexible.
	- <span style="color:#ffc000">Human-agent interaction</span> - seamlessly supports human-agent interaction in both single-agent and multi-agent scenarios, making it possible for one or more humans to communicate and interact with language agents.
		- supports human-agent interaction in multi-agent systems by allowing human users to change the “is_human” field for a certain agent in the config file to “True”. In this case, the user can play the role of the agent by himself/herself and input his/her own actions and interact with other language agents in the environment.
	- <span style="color:#ffc000">Controllabilty</span> - provides a novel paradigm to build controllable agents via a symbolic plan, also referred to as standard operating procedures (SOPs). An SOP is a graph of multiple states that defines different situations an agent may encounter while accomplishing a task, and the transition rules between the states. Similar to SOPs in the real world, an SOP in AGENTS is a meticulously documented set of step-by-step instructions that outlines how a particular task or process should be performed by an agent or a group of agents. SOPs can be generated by an LLM and edited by the user when customizing and tuning the agent. After deployment, an agent will behave following specified instructions and guidelines for each state and dynamically adjust its current state according to its interaction with the environment, humans, or other agents. The introduction of the symbolic plan offers the opportunity to provide fine-grained control of an agent’s behavior, making agents’ behavior more stable/predictable and facilitating tuning/optimizing agents at the same time.
- Existing open-source frameworks for language agents focus on building proof-of-concept language agents that run either in the terminal or on Gradio. In contrast, AGENTS supports deploying language agents as APIs with FastAPI
## Library Design

- AGENTS is designed following the philosophy in Franklin and Graesser “an autonomous agent is situated in an environment”. Therefore, agent and environment are two major classes in the AGENTS framework. In addition to these two classes, we also include a class for symbolic plans, named SOP (short for Standard Operating Procedure), to make language agents more controllable. These main classes are all initialized from a config file which can be filled plain text.  ![](../Images/Pasted%20image%2020231002013940.png)
- The config file not only defines these core objects but also factorizes complicated prompts into modularized prompt components. The factorization of prompts significantly reduces the expertise requirements and efforts for users to build (multi) agent systems. Using a single config file to define the agents, plan, and basic environment also facilitates the sharing of language agents (which will be discussed in the Agent Hub section). Each of these three core classes consist of standardized APIs that can be overwritten by experienced developers and researchers.![](../Images/Pasted%20image%2020231002014201.png)
### Agent
- The Agent class abstracts a language agent. We can see that an agent maintains its long-short term memory and has methods to observe the environment (agent.\_observe(environment)), act according to its current state (agent.\_act()) and update its memory (agent.\_update_memory()). All these methods are wrapped in the agent.step() method.
- Unlike existing language agent frameworks that assume an agent must be based on an LLM, we include a “\_is_human” property to an agent. If it is set to “True”, the (agent.\_act()) will opt to provide observations and memory information to a human user and wait for the human user to input the action. This design allows flexible human-agent interaction in both single-agent and multi-agent systems by allowing human users to take the role of one or more language agents. It facilitates developers to build various interesting applications such as allowing human users to act as members of a team in debate and collaborate with (agent or human-based) teammates to beat another team, or act as CTO/engineers in a software company and collaborate with others for software development.
### SOP
- The SOP class contains a graph of the states of agents. Each state specifies a certain sub-task or sub-goal of all agents when accomplishing the task described by the SOP. States are abstracted into a State class
- A State object contains modularized prompts for the agent to leverage an LLM and various tools or APIs that an agent can use in the state. We abstract everything an agent may use for action in a state into a “Component” class. The Component class consists of two subclasses corresponding to different parts of the prompt and tools or external APIs, named “PromptComponent” and “ToolComponent”, respectively. PromptComponent includes modularized prompts that specify the task/goal, rules/constraints, (step-by-step) demonstrations for in-context learning, and the output format.
- An SOP object also includes an LLM-based control function that decides the transition between different states and the next agent to act. The state transit function is named sop.\_transit() and the agent routing function is named sop.\_route(). Both of the functions are wrapped in an sop.next() function which is used in the main loop.![](../Images/Pasted%20image%2020231002014730.png)
### Environment
- The Environment class abstracts the environment in which the agents are situated. An environment consists of two main functions: environment.\_observed() and environment.update(). environment.\_observed() defines how the environment influences the agent’s action (i.e., what information should be transferred to the agent upon observation, and environment.update() defines how the agent’s action impacts the environment.
- in each iteration, the SOP first decides the state transition and selects the next agent to act based on the agents and the environment. The agent then takes an action based on its state and the environment. Then the environment updates itself based on the new action. Finally, if a workflow requires dynamically adjusting the plan based on the intermediate execution results, one can parse the output from an action, define a new state and add it into the current SOP
![](../Images/Pasted%20image%2020231002014911.png)![](../Images/Pasted%20image%2020231002015252.png)

